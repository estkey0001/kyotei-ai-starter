import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
import joblib

print("ğŸ¯ å®Ÿç”¨çš„é«˜ç²¾åº¦ç«¶è‰‡äºˆæƒ³ã‚·ã‚¹ãƒ†ãƒ ")

df = pd.read_csv('data/coconala_2024/toda_2024.csv')
print(f"ãƒ‡ãƒ¼ã‚¿: {df.shape}")

# ã‚·ãƒ³ãƒ—ãƒ«ç‰¹å¾´é‡é¸æŠï¼ˆæœ€é‡è¦é …ç›®ã®ã¿ï¼‰
features = []
targets = []

target_cols = ['finish_position_1', 'finish_position_2', 'finish_position_3', 
               'finish_position_4', 'finish_position_5', 'finish_position_6']

for idx, row in df.iterrows():
    positions = [row[col] for col in target_cols if pd.notna(row[col])]
    if 1.0 in positions:
        winner = positions.index(1.0)
        targets.append(winner)
        
        # æ ¸å¿ƒç‰¹å¾´é‡ã®ã¿
        feature_row = []
        
        for i in range(1, 7):
            # æœ€é‡è¦3è¦ç´ 
            win_rate = float(row.get(f'win_rate_national_{i}', 5)) if pd.notna(row.get(f'win_rate_national_{i}')) else 5
            class_val = {'A1': 4, 'A2': 3, 'B1': 2, 'B2': 1}.get(row.get(f'racer_class_{i}', 'B1'), 2)
            motor_rate = float(row.get(f'motor_win_rate_{i}', 35)) if pd.notna(row.get(f'motor_win_rate_{i}')) else 35
            
            feature_row.extend([win_rate, class_val, motor_rate])
        
        features.append(feature_row)

X = np.array(features)
y = np.array(targets)

print(f"æœ€é©åŒ–ãƒ‡ãƒ¼ã‚¿: {len(X)}ãƒ¬ãƒ¼ã‚¹, {X.shape[1]}ç‰¹å¾´é‡")

# å‰å‡¦ç†
imputer = SimpleImputer(strategy='median')
X = imputer.fit_transform(X)

scaler = StandardScaler()
X = scaler.fit_transform(X)

# å­¦ç¿’
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# æœ€é©åŒ–RandomForest
model = RandomForestClassifier(
    n_estimators=500,
    max_depth=20, 
    min_samples_split=3,
    min_samples_leaf=2,
    class_weight='balanced_subsample',
    random_state=42,
    n_jobs=-1
)

model.fit(X_train, y_train)
pred = model.predict(X_test)
accuracy = accuracy_score(y_test, pred)

print(f"\nğŸ† æœ€çµ‚ç²¾åº¦: {accuracy:.4f} ({accuracy*100:.1f}%)")

# å®Ÿç”¨çš„ãªäºˆæ¸¬é–¢æ•°ä½œæˆ
def predict_race(racer_data):
    """
    6è‰‡ã®ãƒ¬ãƒ¼ã‚¹äºˆæ¸¬
    racer_data: [(win_rate, class, motor_rate), ...] 6è‰‡åˆ†
    """
    feature_vector = []
    for win_rate, racer_class, motor_rate in racer_data:
        class_val = {'A1': 4, 'A2': 3, 'B1': 2, 'B2': 1}.get(racer_class, 2)
        feature_vector.extend([win_rate, class_val, motor_rate])
    
    X_pred = np.array([feature_vector])
    X_pred = imputer.transform(X_pred)
    X_pred = scaler.transform(X_pred)
    
    probabilities = model.predict_proba(X_pred)[0]
    prediction = model.predict(X_pred)[0]
    
    return prediction + 1, probabilities  # 1-6å·è‰‡ã«å¤‰æ›

# ãƒ†ã‚¹ãƒˆäºˆæ¸¬
print("\nğŸ§ª äºˆæ¸¬ãƒ†ã‚¹ãƒˆ:")
test_data = [
    (7.2, 'A1', 45.0),  # 1å·è‰‡: é«˜å‹ç‡A1ç´š
    (5.8, 'A2', 38.0),  # 2å·è‰‡: ä¸­å‹ç‡A2ç´š
    (4.2, 'B1', 32.0),  # 3å·è‰‡: ä½å‹ç‡B1ç´š
    (3.8, 'B1', 28.0),  # 4å·è‰‡
    (2.9, 'B2', 25.0),  # 5å·è‰‡
    (2.1, 'B2', 22.0),  # 6å·è‰‡
]

predicted_winner, probs = predict_race(test_data)
print(f"äºˆæƒ³1ç€: {predicted_winner}å·è‰‡")
print("å„è‰‡ç¢ºç‡:")
for i, prob in enumerate(probs):
    print(f"  {i+1}å·è‰‡: {prob:.3f} ({prob*100:.1f}%)")

# ä¿å­˜
joblib.dump({
    'model': model,
    'imputer': imputer,
    'scaler': scaler,
    'predict_function': predict_race
}, 'practical_kyotei_model.pkl')

print(f"\nğŸ’¾ å®Ÿç”¨ãƒ¢ãƒ‡ãƒ«ä¿å­˜: practical_kyotei_model.pkl")
print("ğŸ‰ å®Ÿç”¨ã‚·ã‚¹ãƒ†ãƒ å®Œæˆï¼")
